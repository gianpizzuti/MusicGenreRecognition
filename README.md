The aim of this project is to present a method to automatically identify the genre of mu- sical clips. The genre is an abstract feature, but still, it is considered to be an important characteristics of music. Existing algorithms for genre recognition predominantly rely on feature extraction techniques. These extracted characteristics are then utilized to build a classifier on the genre label. However, genre is a fuzzy concept which is also subject to per- sonal interpretation, and there may be overlapping of genres in the same song. For these reasons, genre recognition is an inherently difficult task, and the accuracy of a classifier based on the extracted features can be very sensitive to the datasets on which it is trained and tested. In our project, we utilize a pipeline for extracting mel-spectrogram features from audio clips coming from the popular GTZAN dataset, and subsequently build a classifier for the genre. The classifier model is based on a convolutional recurrent neural network architecture, and is trained on the dataset of the extracted mel-spectrograms, after a train-validation-test split of 80%, 10% and 10% respectively. Our model reaches an accuracy of around 73% in 25 epochs in the test set.
